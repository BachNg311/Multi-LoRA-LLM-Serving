services:
  vllm:
    image: vllm/vllm-openai:v0.15.0
    container_name: vllm
    entrypoint: ["/bin/bash", "/app/entrypoint.sh"]
    # runtime: nvidia
    # environment:
    #   - NVIDIA_VISIBLE_DEVICES=all
    #   - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    env_file:
      - .env
    ports:
      - "8000:8000"
    volumes:
      - huggingface_cache:/root/.cache/huggingface
      - vllm_cache:/root/.cache/vllm
      - ./entrypoint.sh:/app/entrypoint.sh
      - ./adapters.sh:/app/adapters.sh
      - ./download_adapters.py:/app/download_adapters.py
      - ../benchmarks:/app/benchmarks
    networks:
      - aio-network
    logging:
      driver: loki
      options:
        loki-url: "http://localhost:3100/loki/api/v1/push"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

volumes:
  huggingface_cache:
  vllm_cache:

networks:
  aio-network:
    external: true
